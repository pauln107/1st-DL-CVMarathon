{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 373s 7ms/step - loss: 1.5100 - acc: 0.4731\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 370s 7ms/step - loss: 1.0633 - acc: 0.6240\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 375s 7ms/step - loss: 0.9149 - acc: 0.6800\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 375s 8ms/step - loss: 0.8222 - acc: 0.7126\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 374s 7ms/step - loss: 0.7513 - acc: 0.7373\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 373s 7ms/step - loss: 0.6636 - acc: 0.7694\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.5895 - acc: 0.7946\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.5130 - acc: 0.8210\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.4450 - acc: 0.8448\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.3775 - acc: 0.8698\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.3160 - acc: 0.8912\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.2669 - acc: 0.9082\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.2279 - acc: 0.9211\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.1929 - acc: 0.9345\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.1667 - acc: 0.9428\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.1464 - acc: 0.9500\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.1272 - acc: 0.9580\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.1038 - acc: 0.9650\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.1081 - acc: 0.9632\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.1142 - acc: 0.9618\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.0941 - acc: 0.9684\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.0881 - acc: 0.9700\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.0730 - acc: 0.9755\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.0646 - acc: 0.9781\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.0640 - acc: 0.9780\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.0852 - acc: 0.9700\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.0795 - acc: 0.9733\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.0603 - acc: 0.9803\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.0603 - acc: 0.9797\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 379s 8ms/step - loss: 0.0554 - acc: 0.9811\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 379s 8ms/step - loss: 0.0554 - acc: 0.9808\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.0603 - acc: 0.9799\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 362s 7ms/step - loss: 0.0607 - acc: 0.9794\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 362s 7ms/step - loss: 0.0489 - acc: 0.9836\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 363s 7ms/step - loss: 0.0446 - acc: 0.9857\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 368s 7ms/step - loss: 0.0404 - acc: 0.9863\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 372s 7ms/step - loss: 0.0517 - acc: 0.9831\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 370s 7ms/step - loss: 0.0545 - acc: 0.9820\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 374s 7ms/step - loss: 0.0400 - acc: 0.9867\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.0418 - acc: 0.9863\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 372s 7ms/step - loss: 0.0422 - acc: 0.9861\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 372s 7ms/step - loss: 0.0386 - acc: 0.9873\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 375s 7ms/step - loss: 0.0424 - acc: 0.9868\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 376s 8ms/step - loss: 0.0372 - acc: 0.9876\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 375s 8ms/step - loss: 0.0392 - acc: 0.9873\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.0450 - acc: 0.9851\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 408s 8ms/step - loss: 0.0324 - acc: 0.9895\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 408s 8ms/step - loss: 0.0383 - acc: 0.9874\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 395s 8ms/step - loss: 0.0347 - acc: 0.9888\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 399s 8ms/step - loss: 0.0381 - acc: 0.9876\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 396s 8ms/step - loss: 0.0433 - acc: 0.9862\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 391s 8ms/step - loss: 0.0355 - acc: 0.9879\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 405s 8ms/step - loss: 0.0316 - acc: 0.9903\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 413s 8ms/step - loss: 0.0282 - acc: 0.9908\n",
      "Epoch 55/100\n",
      "  500/50000 [..............................] - ETA: 6:31 - loss: 0.0164 - acc: 0.9960"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, (3,3), input_shape=(32,32,3), activation='relu'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(64, (3,3)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(units=100, activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "classifier.fit(x_train,y_train, batch_size=100, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
